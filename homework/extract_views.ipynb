{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Edits Data Pipeline\n",
    "\n",
    "This notebook demonstrates a simple ETL pipeline that:\n",
    "1. Extracts data from the Wikipedia REST API\n",
    "2. Transforms it to JSON Lines format\n",
    "3. Uploads directly to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your username here - use it consistently across all resources\n",
    "USERNAME = \"nahian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract: Retrieve Data from Wikipedia API\n",
    "\n",
    "We use the Wikimedia Analytics API to fetch the most edited pages for a specific date. The API returns JSON with page titles and edit counts.\n",
    "\n",
    "**API Documentation:** https://doc.wikimedia.org/generated-data-platform/aqs/analytics-api/reference/edits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting REST API URL: https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia.org/all-access/2025/11/25\n",
      "Wikipedia REST API Response body: {\"items\":[{\"project\":\"en.wikipedia\",\"access\":\"all-access\",\"year\":\"2025\",\"month\":\"11\",\"day\":\"25\",\"articles\":[{\"article\":\"Main_Page\",\"views\":6343624,\"rank\":1},{\"article\":\"Special:Search\",\"views\":867370,\"rank\":2},{\"article\":\"Dharmendra\",\"views\":386721,\"rank\":3},{\"article\":\"Sawyer_Sweeten\",\"views\":314428,\"rank\":4},{\"article\":\"Google_Chrome\",\"views\":308826,\"rank\":5},{\"article\":\"Wikipedia:Featured_pictures\",\"views\":259967,\"rank\":6},{\"article\":\"Richard_Branson\",\"views\":160194,\"rank\":7},{\"article\":\"Wick...\n",
      "Wikipedia REST API Response Code: 200\n",
      "Successfully retrieved Wikipedia data, content-length: 55589\n"
     ]
    }
   ],
   "source": [
    "# Try different dates to see how the data changes\n",
    "DATE_PARAM = \"2025-11-25\"\n",
    "\n",
    "date = datetime.datetime.strptime(DATE_PARAM, \"%Y-%m-%d\")\n",
    "\n",
    "# Construct the API URL\n",
    "url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia.org/all-access/{date.strftime('%Y/%m/%d')}\"\n",
    "print(f\"Requesting REST API URL: {url}\")\n",
    "\n",
    "# Make the API request\n",
    "wiki_server_response = requests.get(url, headers={\"User-Agent\": \"curl/7.68.0\"})\n",
    "wiki_response_status = wiki_server_response.status_code\n",
    "wiki_response_body = wiki_server_response.text\n",
    "\n",
    "print(f\"Wikipedia REST API Response body: {wiki_response_body[:500]}...\")\n",
    "print(f\"Wikipedia REST API Response Code: {wiki_response_status}\")\n",
    "\n",
    "# Validate response\n",
    "if wiki_response_status != 200:\n",
    "    raise Exception(f\"Received non-OK status code from Wiki Server: {wiki_response_status}\")\n",
    "print(f\"Successfully retrieved Wikipedia data, content-length: {len(wiki_response_body)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform: Process Raw Data into JSON Lines\n",
    "\n",
    "Convert the raw API response into a structured JSON Lines format suitable for analytics. Each line is a valid JSON object representing one page's edit statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1000 records to JSON Lines\n",
      "First few lines:\n",
      "{\"title\": \"Main_Page\", \"views\": 6343624, \"rank\": 1, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-19T18:34:47.056078\"}\n",
      "{\"title\": \"Special:Search\", \"views\": 867370, \"rank\": 2, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-19T18:34:47.056078\"}\n",
      "{\"title\": \"Dharmendra\", \"views\": 386721, \"rank\": 3, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-19T18:34:47.056078\"}\n",
      "{\"title\": \"Sawyer_Sweeten\", \"views\": 314428, \"rank\": 4, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-19T18:34:47.056078\"}\n",
      "{\"title\": \"G...\n"
     ]
    }
   ],
   "source": [
    "# Parse the API response and extract top edits\n",
    "wiki_response_parsed = wiki_server_response.json()\n",
    "top_views = wiki_response_parsed[\"items\"][0][\"articles\"]\n",
    "\n",
    "# Transform to JSON Lines format\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "json_lines = \"\"\n",
    "for page in top_views[:5]:\n",
    "    record = {\n",
    "        \"title\": page[\"article\"],\n",
    "        \"views\": page[\"views\"],\n",
    "        \"rank\": page[\"rank\"],\n",
    "        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "        \"retrieved_at\": current_time.replace(tzinfo=None).isoformat(),\n",
    "    }\n",
    "    json_lines += json.dumps(record) + \"\\n\"\n",
    "\n",
    "print(f\"Transformed {len(top_views)} records to JSON Lines\")\n",
    "print(f\"First few lines:\\n{json_lines[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 1: Create an S3 Bucket\n",
    "\n",
    "**Task:** Create an S3 bucket for the Wikipedia data pipeline.\n",
    "\n",
    "**Requirements:**\n",
    "- Bucket name: `<username>-wikidata` (use your USERNAME from above)\n",
    "- Create the bucket if it doesn't exist\n",
    "\n",
    "**Documentation:** [create_bucket](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/create_bucket.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing bucket: nahian-wikidata\n"
     ]
    }
   ],
   "source": [
    "S3_WIKI_BUCKET = \"nahian-wikidata\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "bucket_names = [bucket[\"Name\"] for bucket in s3.list_buckets()[\"Buckets\"]]\n",
    "if S3_WIKI_BUCKET not in bucket_names:\n",
    "    # LAB 1: Create the bucket if it doesn't exist\n",
    "    # YOUR SOLUTION COMES HERE =========================\n",
    "    default_region = \"eu-west-1\"\n",
    "    bucket_configuration = {\"LocationConstraint\": default_region}\n",
    "    response = s3.create_bucket(Bucket= S3_WIKI_BUCKET, CreateBucketConfiguration=bucket_configuration)\n",
    "    # ==================================================\n",
    "    print(f\"Created new bucket: {S3_WIKI_BUCKET}\")\n",
    "else:\n",
    "    print(f\"Using existing bucket: {S3_WIKI_BUCKET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket nahian-wikidata exists!\n"
     ]
    }
   ],
   "source": [
    "# Test Lab 1\n",
    "assert USERNAME != \"nahian-wikipedia\", \"Please set your USERNAME at the top of the notebook\"\n",
    "assert S3_WIKI_BUCKET.endswith(\"-wikidata\"), \"Bucket name must end with '-wikidata'\"\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=S3_WIKI_BUCKET)\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} exists!\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} not found: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 2: Upload JSON Lines to S3\n",
    "\n",
    "**Task:** Upload the `json_lines` data directly to S3 (no local file!).\n",
    "\n",
    "**Requirements:**\n",
    "- Use `s3.put_object()` to upload the data directly\n",
    "- Place the file under `raw-edits/` prefix in S3\n",
    "- File name: `raw-edits-YYYY-MM-DD.json` (use the date from `DATE_PARAM`)\n",
    "\n",
    "**Example S3 path:** `s3://johndoe-wikidata/raw-edits/raw-edits-2025-11-25.json`\n",
    "\n",
    "**Documentation:** [put_object](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_object.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0NYM8AMJMFQHNVVH',\n",
       "  'HostId': '2cemRRgw/ZLEUa6yKHkNVI39nDa6ZG+5YCW1q7uF38tjIJ90c4V5lAhZlkO5Rv2+FSs6vQ0jHEs=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '2cemRRgw/ZLEUa6yKHkNVI39nDa6ZG+5YCW1q7uF38tjIJ90c4V5lAhZlkO5Rv2+FSs6vQ0jHEs=',\n",
       "   'x-amz-request-id': '0NYM8AMJMFQHNVVH',\n",
       "   'date': 'Fri, 19 Dec 2025 18:34:48 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"4130b2195513992670e90decb8f7db74\"',\n",
       "   'x-amz-checksum-crc32': 'fh187A==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"4130b2195513992670e90decb8f7db74\"',\n",
       " 'ChecksumCRC32': 'fh187A==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAB 2: Upload json_lines directly to S3\n",
    "\n",
    "s3_key = f\"raw-views/raw-views-{DATE_PARAM}.json\"\n",
    "\n",
    "# Upload the json_lines string directly to S3\n",
    "s3.put_object(\n",
    "    Bucket=S3_WIKI_BUCKET,\n",
    "    Key=s3_key,\n",
    "    Body=json_lines,\n",
    "    ContentType=\"application/json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully to s3://nahian-wikidata/raw-views/raw-views-2025-11-25.json\n"
     ]
    }
   ],
   "source": [
    "# Test Lab 2\n",
    "expected_key = f\"raw-views/raw-views-{date.strftime('%Y-%m-%d')}.json\"\n",
    "\n",
    "try:\n",
    "    s3.head_object(Bucket=S3_WIKI_BUCKET, Key=expected_key)\n",
    "    print(f\"File uploaded successfully to s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"File not found at s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
